{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Organizing files in different folders for testing and training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    \"\"\"\n",
    "    response = filename for input\n",
    "    destination = filename for output\n",
    "    \"\"\"    \n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the google drive file into a zipped folder on your computer called ```NWPU_images.zip```. This should be 405 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '14kkcuU6wd9UMvjaDrg3PNI-e_voCi8HL'\n",
    "destination = 'NWPU_images.zip'\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using system commands to work with the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the folder (this may take a few minutes) as a new folder called ```images```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def unzip_nwpu(f):\n",
    "    \"\"\"\n",
    "    f = file to be unzipped\n",
    "    \"\"\"    \n",
    "    with zipfile.ZipFile(f, 'r') as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_nwpu(destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file sysem utilities for moving and deleting files (```os``` and ```shutil```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the ```images``` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.rename('images','nwpu_images')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-lake directories that we won't need. First find all subdirectories (except the first, which is the parent directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirecs = [x[0] for x in os.walk('nwpu_images')][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then get a list of all subdirectories that do not contain the word \"lake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = [s for s in subdirecs if 'lake' not in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ```shutil.rmtree``` to delete the imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in to_delete:\n",
    "    shutil.rmtree(k, ignore_errors=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, rename the subdirectory, for consistency with dataset 1. It will become apparent why we use the ```data``` subdirectory in Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('nwpu_images'+os.sep+'lake','nwpu_images'+os.sep+'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, glob, os\n",
    "\n",
    "## create a directory to move the images into. It is wrapped in a \"try:except\" loop \n",
    "## in case you have run this cell before and want to avoid errors\n",
    "try:\n",
    "    os.mkdir('nwpu_images'+os.sep+'data'+os.sep+'Testing')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a directory to move the images into. It is wrapped in a \"try:except\" loop \n",
    "## in case you have run this cell before and want to avoid errors\n",
    "try:\n",
    "    os.mkdir('nwpu_images'+os.sep+'data'+os.sep+'Training')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and testing data using regular expression.  Files labelled 001 to 599 are part of training and ones labelled 600 to 700 are part of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rdubey\\Desktop\\DeepLearningSatelliteImage\\Buscombe_liveProject_Feb2020\\2_Data\\nwpu_images\\data\n",
      "c:\\Users\\rdubey\\Desktop\\DeepLearningSatelliteImage\\Buscombe_liveProject_Feb2020\\2_Data\\nwpu_images\\data\n"
     ]
    }
   ],
   "source": [
    "import shutil, glob, os, re\n",
    "# cycle through each jpg image in the current directory\n",
    "print (os.getcwd())\n",
    "os.chdir('c:\\\\Users\\\\rdubey\\\\Desktop\\\\DeepLearningSatelliteImage\\\\Buscombe_liveProject_Feb2020\\\\2_Data\\\\nwpu_images\\\\data')\n",
    "print (os.getcwd())\n",
    "f = []\n",
    "path = os.getcwd()\n",
    "f = os.listdir(path)\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    for file in f:\n",
    "        #print (f)\n",
    "        #print (len(f))\n",
    "        \n",
    "        #move to the new directory\n",
    "        if re.match (r'lake+_+[0-5]+\\d\\d+\\.+jpg', file):\n",
    "            shutil.copy(file,'c:\\\\Users\\\\rdubey\\\\Desktop\\\\DeepLearningSatelliteImage\\\\Buscombe_liveProject_Feb2020\\\\2_Data\\\\nwpu_images\\\\data\\\\Training' )\n",
    "            #print (f)\n",
    "        else: \n",
    "            shutil.copy(file, 'c:\\\\Users\\\\rdubey\\\\Desktop\\\\DeepLearningSatelliteImage\\\\Buscombe_liveProject_Feb2020\\\\2_Data\\\\nwpu_images\\\\data\\\\Testing' )\n",
    "except:\n",
    "    pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, a note about labels\n",
    "If you have developed your own geospatial data sets in this way, you may find the [European Commission’s Global Surface Water Explorer](https://global-surface-water.appspot.com/) high-resolution label (“ground-truth”) data very useful. Using this dataset will likely require some familiarity with GIS such as [QGIS](https://qgis.org/en/site/) or geospatial processing such as [GDAL for python](https://pypi.org/project/GDAL/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
